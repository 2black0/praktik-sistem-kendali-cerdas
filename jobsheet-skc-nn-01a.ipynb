{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d5e0f9-979a-4f77-8e84-32619021a767",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3df58d-0dc7-4732-8585-871c031b0ad0",
   "metadata": {},
   "source": [
    "Neural network atau jaringan saraf adalah model matematika yang terinspirasi dari cara kerja otak manusia. Model ini terdiri dari banyak unit kecil yang disebut \"neuron\" yang terhubung satu sama lain melalui jaringan koneksi yang kompleks. Setiap neuron menerima input dari neuron lainnya dan menghasilkan output berdasarkan fungsi aktivasi yang ditentukan. Output dari satu neuron kemudian menjadi input untuk neuron lainnya, membentuk rangkaian pemrosesan informasi yang kompleks.\n",
    "\n",
    "Neural network digunakan dalam berbagai aplikasi seperti pengenalan gambar, pengenalan suara, pemrosesan bahasa alami, analisis data, dan banyak lagi. Dalam pembelajaran mesin, neural network digunakan untuk mengekstraksi fitur dari data dan mempelajari hubungan yang kompleks antara input dan output. Proses pembelajaran ini melibatkan menyesuaikan bobot koneksi antara neuron untuk mencapai hasil yang diinginkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14196594-9d4e-41bf-ae7f-b0d8eeff1d7e",
   "metadata": {},
   "source": [
    "## Aplikasi neural network di berbagai bidang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04fa4b-1bf5-485f-9a1d-a59df3c80875",
   "metadata": {},
   "source": [
    "1. Computer Vision\n",
    "Neural network digunakan dalam pengenalan gambar dan video. Contohnya, convolutional neural network (CNN) digunakan untuk klasifikasi gambar dan deteksi objek dalam gambar. Salah satu aplikasi yang populer adalah deteksi wajah pada kamera CCTV dan kamera smartphone.\n",
    "\n",
    "2. Natural Language Processing\n",
    "Neural network digunakan untuk pemrosesan bahasa alami seperti penerjemahan mesin, analisis sentimen, dan pengenalan suara. Contohnya, recurrent neural network (RNN) digunakan untuk penerjemahan mesin dan speech recognition.\n",
    "\n",
    "3. Medicine\n",
    "Neural network digunakan dalam diagnosis medis, penelitian obat, dan pengobatan pasien. Contohnya, neural network digunakan untuk memprediksi hasil tes medis dan mengidentifikasi pasien yang berisiko terkena penyakit tertentu.\n",
    "\n",
    "4. Keuangan\n",
    "Neural network digunakan dalam prediksi harga saham, deteksi kecurangan, dan analisis risiko. Contohnya, neural network digunakan untuk mengidentifikasi pola dalam data pasar saham dan memprediksi harga saham di masa depan.\n",
    "\n",
    "5. Teknologi\n",
    "Neural network digunakan dalam berbagai teknologi seperti self-driving car, pengenalan suara dan tulisan tangan, dan asisten virtual. Contohnya, neural network digunakan untuk mengenali objek dan pergerakan di sekitar mobil otonom.\n",
    "\n",
    "6. Industri\n",
    "Neural network digunakan dalam otomatisasi dan optimasi proses industri seperti manufaktur dan transportasi. Contohnya, neural network digunakan untuk memprediksi kegagalan mesin dan memperbaiki proses produksi.\n",
    "\n",
    "7. Gaming\n",
    "Neural network digunakan dalam game untuk membuat bot yang cerdas dan beradaptasi dengan permainan. Contohnya, neural network digunakan dalam game catur dan game strategi lainnya untuk membuat bot yang bisa belajar dan meningkatkan kemampuan permainannya.\n",
    "\n",
    "Dalam setiap aplikasi, neural network membantu menyelesaikan masalah yang kompleks dan mempercepat proses pengambilan keputusan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf10b7-b063-4a83-9c9b-4932f9479d3e",
   "metadata": {},
   "source": [
    "## Dasar-dasar Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66fd0d7-ddfe-4939-bd6c-f8877fbffac7",
   "metadata": {},
   "source": [
    "![alternative text](images/basic-neural-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a72fdf-350f-4039-9749-8d6491c306f1",
   "metadata": {},
   "source": [
    "Berikut adalah bagian-bagian dari neural network beserta penjelasannya:\n",
    "\n",
    "1. Input layer\n",
    "Input layer adalah bagian pertama dari neural network, yang menerima input data dalam bentuk vektor. Vektor input tersebut bisa berisi data seperti piksel gambar, angka, atau variabel lainnya.\n",
    "\n",
    "2. Hidden layer\n",
    "Hidden layer adalah layer di antara input layer dan output layer. Hidden layer terdiri dari beberapa neuron yang menerima input dari input layer dan menghasilkan output yang kemudian menjadi input untuk output layer. Jumlah hidden layer dan jumlah neuron di dalam setiap layer tergantung pada kompleksitas tugas yang ingin diselesaikan.\n",
    "\n",
    "3. Output layer\n",
    "Output layer adalah layer terakhir dari neural network yang menghasilkan output dari proses pemrosesan input. Output layer dapat menghasilkan satu nilai (dalam kasus regresi) atau beberapa nilai yang merepresentasikan kategori (dalam kasus klasifikasi).\n",
    "\n",
    "4. Bobot\n",
    "Bobot adalah variabel yang digunakan untuk menghubungkan neuron dalam satu layer dengan neuron di layer berikutnya. Bobot menggambarkan kekuatan koneksi antara neuron dalam satu layer dengan neuron di layer berikutnya. Selama proses pelatihan, bobot diatur sedemikian rupa sehingga neural network dapat menghasilkan output yang akurat.\n",
    "\n",
    "5. Fungsi aktivasi\n",
    "Fungsi aktivasi adalah fungsi matematis yang diterapkan pada output neuron dalam satu layer untuk menghasilkan output yang lebih berguna. Fungsi aktivasi umumnya non-linear dan beragam, seperti sigmoid, relu, dan tanh.\n",
    "\n",
    "6. Pelatihan\n",
    "Pelatihan adalah proses untuk mengoptimalkan bobot dalam neural network untuk menghasilkan output yang tepat. Proses pelatihan ini melibatkan perhitungan biaya (cost) dari output neural network yang dihasilkan dan memperbarui bobot jaringan dengan algoritma pelatihan yang sesuai seperti backpropagation dan stochastic gradient descent.\n",
    "\n",
    "7. Validasi dan evaluasi\n",
    "Setelah pelatihan, neural network perlu diuji pada data validasi yang belum pernah dilihat sebelumnya. Evaluasi dilakukan dengan menggunakan metrik seperti akurasi, presisi, recall, atau F1-score.\n",
    "\n",
    "Dalam setiap aplikasi, bagian-bagian neural network dapat berbeda-beda tergantung pada arsitektur dan kompleksitas tugas yang ingin diselesaikan. Namun, dasar-dasar tersebut tetap ada dan perlu dipahami untuk merancang dan mengoptimalkan neural network yang sesuai dengan tugas yang ingin diselesaikan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b54ed6-6032-4170-ba75-78cde40462f3",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d7a48-3012-4fb6-8e04-905cb40975f6",
   "metadata": {},
   "source": [
    "![alternative text](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54529f8f-5356-4165-b94f-b4c3bee2fce0",
   "metadata": {},
   "source": [
    "Perceptron adalah salah satu jenis model neural network yang sangat sederhana dan awalnya dikembangkan oleh Frank Rosenblatt pada tahun 1957. Perceptron terdiri dari satu layer input dan satu layer output yang berfungsi sebagai klasifikasi biner (binary classifier), yaitu mengelompokkan input ke dalam dua kelas yang berbeda. Perceptron digunakan untuk mempelajari hubungan linier antara input dan output, dengan menggunakan prinsip pembelajaran berupa \"melatih\" model dengan memberikan contoh input dan output yang telah diketahui. Kemudian, model tersebut dapat digunakan untuk melakukan prediksi pada data yang belum pernah dilihat sebelumnya.\n",
    "\n",
    "Perceptron bekerja dengan cara mengalikan setiap nilai input dengan bobotnya, kemudian menjumlahkan hasil perkalian tersebut dan menambahkan bias. Hasil akhir dari operasi tersebut kemudian dijadikan input untuk fungsi aktivasi, seperti fungsi step atau sigmoid. Output yang dihasilkan dari fungsi aktivasi akan digunakan untuk menentukan kelas output yang sesuai dengan input yang diberikan.\n",
    "\n",
    "Pada awalnya, perceptron hanya dapat digunakan untuk menyelesaikan masalah yang linearly separable, yaitu masalah di mana kelas input dapat dipisahkan dengan garis lurus pada ruang input. Namun, kemudian perceptron dikembangkan lebih lanjut dengan menggunakan beberapa layer yang lebih kompleks, sehingga dapat menyelesaikan masalah yang lebih kompleks seperti masalah non-linear. Perceptron multilayer yang lebih kompleks disebut sebagai neural network feedforward dengan banyak hidden layer, atau sering disebut sebagai deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa8047-63f2-4ea6-9108-553cb1fc844b",
   "metadata": {},
   "source": [
    "Bias dalam neural network merupakan parameter tambahan yang berfungsi untuk menambah fleksibilitas dan kemampuan model untuk belajar dari data yang diberikan. Bias diperlukan agar model dapat menangkap pola-pola yang kompleks dan tidak linier dari data yang ada. Bias dihitung dengan cara menambahkan konstanta ke dalam output neuron, sehingga memungkinkan neuron tersebut untuk mengaktifkan atau tidak mengaktifkan dirinya sendiri tergantung pada bobot inputannya. Dalam neural network, bias merupakan suatu nilai yang ditambahkan ke dalam jumlah produk titik antara input dan bobot, sebelum hasilnya diolah oleh fungsi aktivasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960bacd-331d-4dd6-b614-4529effe4290",
   "metadata": {},
   "source": [
    "## Contoh perhitungan sederhana Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf8e08-8b78-43e9-8f96-e71549888f5d",
   "metadata": {},
   "source": [
    "Berikut adalah contoh perhitungan neural network yang sangat sederhana dengan hanya satu input layer dan satu output layer:\n",
    "\n",
    "Kita akan membuat neural network yang dapat memprediksi apakah seseorang diterima atau tidak diterima di suatu universitas berdasarkan nilai tes masuk yang dimilikinya. Nilai tes masuk yang dimiliki seseorang akan menjadi input untuk neural network, dan outputnya akan menunjukkan apakah orang tersebut diterima atau tidak.\n",
    "\n",
    "Kita akan menggunakan fungsi aktivasi sigmoid untuk menghitung output dari setiap node pada output layer. Bobot yang akan digunakan pada output layer adalah 0.5 dan bias adalah -0.3. Kita juga asumsikan bahwa nilai tes masuk seseorang adalah 0.8.\n",
    "\n",
    "Pertama, kita hitung nilai net input pada node pada output layer:\n",
    "net input = (input nilai tes masuk * bobot) + bias\n",
    "= (0.8 * 0.5) - 0.3\n",
    "= 0.1\n",
    "\n",
    "Selanjutnya, kita gunakan fungsi aktivasi sigmoid pada nilai net input:\n",
    "output = 1 / (1 + exp(-net input))\n",
    "= 1 / (1 + exp(-0.1))\n",
    "= 0.525\n",
    "\n",
    "Output 0.525 menunjukkan bahwa kemungkinan seseorang diterima di universitas tersebut adalah sekitar 52,5%.\n",
    "\n",
    "Dalam kasus ini, neural network hanya memiliki satu input dan satu output, namun dalam praktiknya neural network dapat memiliki banyak input dan output, serta beberapa hidden layer untuk melakukan ekstraksi fitur dari input sebelum diteruskan ke output layer. Perhitungan yang dilakukan pada setiap node pada neural network dapat menjadi sangat rumit, tergantung pada arsitektur jaringan dan jumlah node yang terlibat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70022884-5120-43b8-a022-4ab5ce16cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000000000003\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# nilai tes masuk seseorang\n",
    "x = 0.8\n",
    "\n",
    "# bobot pada output layer\n",
    "w = 0.5\n",
    "\n",
    "# bias pada output layer\n",
    "b = -0.3\n",
    "\n",
    "# hitung net input pada output layer\n",
    "out = x * w + b\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2432a2c0-6361-4ac1-8724-414700648d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  0.52497918747894\n"
     ]
    }
   ],
   "source": [
    "# hitung output pada output layer menggunakan fungsi aktivasi sigmoid\n",
    "output = 1 / (1 + math.exp(-out))\n",
    "\n",
    "# tampilkan hasil output\n",
    "print(\"Output: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b6787-2740-46d5-84c8-c0c7b37edfb6",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032b3fe-e59d-4966-a2f7-06a6ac3eaa58",
   "metadata": {},
   "source": [
    "![alternative text](images/multilayer-perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de29e16-6b2d-40e7-b336-72dfd2fea950",
   "metadata": {},
   "source": [
    "Multi-layer perceptron (MLP) adalah jenis arsitektur neural network feedforward yang terdiri dari lebih dari satu layer tersembunyi (hidden layer) antara input layer dan output layer. MLP merupakan pengembangan dari perceptron yang sederhana, yang hanya memiliki satu layer input dan satu layer output, sehingga mampu mempelajari pola yang lebih kompleks.\n",
    "\n",
    "Setiap layer pada MLP terdiri dari sejumlah neuron yang terhubung satu sama lain dengan bobot tertentu. Proses pelatihan MLP dilakukan dengan memperbarui bobot antar neuron berdasarkan perbedaan antara output yang dihasilkan dengan output yang diharapkan. Pelatihan MLP biasanya dilakukan dengan algoritma backpropagation, yang menghitung kesalahan (error) antara output yang dihasilkan dengan output yang diharapkan, lalu memperbarui bobot pada masing-masing neuron berdasarkan besarnya kesalahan tersebut.\n",
    "\n",
    "Keunggulan dari MLP adalah kemampuannya untuk mempelajari pola yang kompleks pada data input yang rumit dan tidak linear. Oleh karena itu, MLP sering digunakan untuk memecahkan masalah klasifikasi atau regresi dalam berbagai bidang, seperti pengenalan citra, analisis sentimen, prediksi harga saham, dan sebagainya. Namun, karena kecenderungan overfitting dan kompleksitas yang tinggi, pemilihan arsitektur dan parameter yang tepat sangat penting dalam pembuatan MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e006055-ecb5-498a-8ed8-34786ddbdcd1",
   "metadata": {},
   "source": [
    "## Contoh MLP Feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c10c0-2a4f-46f2-a539-23f6ed5c0859",
   "metadata": {},
   "source": [
    "![alternative text](images/mlp-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944f1b9-7701-43d3-81eb-c13fc1ae9f32",
   "metadata": {},
   "source": [
    "Misalkan kita memiliki input data berupa dua bilangan x1 dan x2, dan kita ingin membangun sebuah multilayer perceptron dengan satu hidden layer yang terdiri dari tiga neuron dan satu output layer yang mengeluarkan output klasifikasi biner (1 atau 0). Kita asumsikan bahwa data input sudah melalui proses normalisasi sehingga memiliki rentang nilai antara 0 dan 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77436ce-6446-4e28-a4fd-97fb47d74931",
   "metadata": {},
   "source": [
    "Input data: x1 = 0.2, x2 = 0.8\n",
    "\n",
    "Bobot dan bias pada hidden layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9b933-b4f6-46b7-9eb8-1a21a4d693e9",
   "metadata": {},
   "source": [
    "W1 = [[0.1, 0.4, -0.3],\n",
    "      [0.3, -0.2, 0.5]]\n",
    "\n",
    "b1 = [0.2, 0.4, -0.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66928986-7d05-4610-9409-039815436450",
   "metadata": {},
   "source": [
    "Bobot dan bias pada output layer:\n",
    "\n",
    "W2 = [[0.2, 0.1, -0.5]]\n",
    "\n",
    "b2 = [-0.1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e4592-6db4-46ab-95de-f8c0eea1478f",
   "metadata": {},
   "source": [
    "Output kelas yang diharapkan: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2431a0-a7dd-443f-baf7-36f044e0f9de",
   "metadata": {},
   "source": [
    "Hidden layer\n",
    "\n",
    "Neuron 1:\n",
    "\n",
    "z1_1 = W1[0,0]*x1 + W1[1,0]*x2 + b1[0]\n",
    "     = 0.1*0.2 + 0.3*0.8 + 0.2\n",
    "     = 0.44\n",
    "\n",
    "\n",
    "a1_1 = sigmoid(z1_1)\n",
    "     = sigmoid(0.44)\n",
    "     = 0.607"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631ab41-34a8-483e-a0bb-b6fe8eb2ddff",
   "metadata": {},
   "source": [
    "Neuron 2:\n",
    "\n",
    "z1_2 = W1[0,1]*x1 + W1[1,1]*x2 + b1[1]\n",
    "     = 0.4*0.2 + (-0.2)*0.8 + 0.4\n",
    "     = 0.24\n",
    "\n",
    "a1_2 = sigmoid(z1_2)\n",
    "     = sigmoid(0.24)\n",
    "     = 0.559\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90645b47-e591-4039-ba37-c37dd8f1acec",
   "metadata": {},
   "source": [
    "Neuron 3:\n",
    "\n",
    "z1_3 = W1[0,2]*x1 + W1[1,2]*x2 + b1[2]\n",
    "     = (-0.3)*0.2 + 0.5*0.8 - 0.5\n",
    "     = 0.1\n",
    "\n",
    "a1_3 = sigmoid(z1_3)\n",
    "     = sigmoid(0.1)\n",
    "     = 0.525\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fe966-8bd8-4cc2-b637-3745d0e61c51",
   "metadata": {},
   "source": [
    "Output layer\n",
    "\n",
    "z2 = W2[0,0]*a1_1 + W2[0,1]*a1_2 + W2[0,2]*a1_3 + b2\n",
    "   = 0.2*0.607 + 0.1*0.559 + (-0.5)*0.525 + (-0.1)\n",
    "   = 0.0044\n",
    "\n",
    "a2 = sigmoid(z2)\n",
    "   = sigmoid(0.0044)\n",
    "   = 0.501\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae89b3-aa55-4cc8-95ad-82288675c5ac",
   "metadata": {},
   "source": [
    "Output dari multilayer perceptron adalah 0.501. Kita dapat membulatkan nilai tersebut ke nilai biner 1 atau 0, tergantung dari ambang batas (threshold) yang kita tentukan. Dalam contoh ini, karena output kelas yang diharapkan adalah 1, maka kita dapat memutuskan bahwa input [0.2, 0.8] akan diklasifikasikan sebagai kelas 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dc1909-3ea4-43f5-953f-ee5996a44252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46269264]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# input data\n",
    "X = np.array([[0.2], [0.8]])\n",
    "\n",
    "# bobot dan bias pada hidden layer\n",
    "W1 = np.array([[0.1, 0.4, -0.3], [0.3, -0.2, 0.5]])\n",
    "b1 = np.array([[0.2], [0.4], [-0.5]])\n",
    "\n",
    "# bobot dan bias pada output layer\n",
    "W2 = np.array([[0.2], [0.1], [-0.5]])\n",
    "b2 = np.array([-0.1])\n",
    "\n",
    "# feedforward\n",
    "hidden_layer = np.dot(W1.T, X) + b1\n",
    "hidden_layer_activation = 1 / (1 + np.exp(-hidden_layer))\n",
    "output_layer = np.dot(W2.T, hidden_layer_activation) + b2\n",
    "output_layer_activation = 1 / (1 + np.exp(-output_layer))\n",
    "\n",
    "print(output_layer_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5b324-bd8b-4f4f-9070-7b98cdebe5c9",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8b91e-3ac0-48ce-9b1b-ed4df4c74d33",
   "metadata": {},
   "source": [
    "Backpropagation Neural Network atau jaringan saraf balik-propagasi adalah jenis jaringan saraf buatan yang menggunakan algoritma backpropagation untuk melakukan pelatihan atau training pada modelnya. Algoritma backpropagation digunakan untuk menentukan bagaimana setiap bobot dan bias pada setiap neuron dalam jaringan saraf perlu diperbarui selama pelatihan.\n",
    "\n",
    "Dalam algoritma backpropagation, input diteruskan ke jaringan saraf dan menghasilkan output. Selanjutnya, output dibandingkan dengan nilai target, dan kesalahan antara output dan target dihitung. Kemudian, kesalahan tersebut dikembalikan ke seluruh jaringan dengan cara dihitung mundur (backpropagation) melalui setiap lapisan, sehingga setiap neuron dapat memperbarui bobot dan biasnya sesuai dengan kontribusinya terhadap kesalahan.\n",
    "\n",
    "Dalam proses pelatihan jaringan, algoritma backpropagation akan menyesuaikan bobot dan bias pada setiap neuron dalam jaringan untuk meminimalkan kesalahan antara output yang dihasilkan oleh jaringan dan target yang diinginkan. Proses ini dilakukan secara iteratif, di mana pada setiap iterasi, input diteruskan melalui jaringan, kesalahan dihitung, dan bobot dan bias diperbarui untuk meningkatkan akurasi jaringan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175d98e-38a9-414b-8151-5cc6e060f782",
   "metadata": {},
   "source": [
    "Learning rate atau tingkat pembelajaran adalah salah satu parameter penting dalam algoritma pembelajaran mesin yang menggunakan optimasi gradien. Learning rate adalah sebuah angka yang menentukan seberapa besar langkah pembelajaran yang diambil dalam menemukan nilai optimum dari fungsi objektif yang sedang dioptimasi.\n",
    "\n",
    "Secara umum, learning rate mengontrol seberapa besar perubahan pada bobot dan bias yang diterapkan pada setiap iterasi saat menyesuaikan model agar lebih cocok dengan data latih. Jika learning rate terlalu kecil, maka model akan konvergen lebih lambat dan membutuhkan lebih banyak iterasi untuk mencapai hasil yang optimal. Sebaliknya, jika learning rate terlalu besar, model dapat \"melompati\" atau melewati titik optimal dan tidak dapat mencapai hasil yang baik. Oleh karena itu, pemilihan learning rate yang tepat adalah penting untuk memastikan model dapat dikonvergen secara efektif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6976d07-8abf-4594-9b2e-2ff838504e80",
   "metadata": {},
   "source": [
    "## Contoh Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fbeea-db89-4cec-9024-15c1e131d533",
   "metadata": {},
   "source": [
    "https://www.javatpoint.com/pytorch-backpropagation-process-in-deep-neural-network\n",
    "\n",
    "https://hmkcode.com/ai/backpropagation-step-by-step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e040e4-8737-47cd-ba3b-d5ad7029edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awal\n",
      " [[-0.082978    0.22032449]\n",
      " [-0.49988563 -0.19766743]] [[-0.35324411]\n",
      " [-0.40766141]] [[-0.31373979 -0.15443927]] [[-0.10323253]]\n",
      "\n",
      "\n",
      "Output setelah training:\n",
      "[[0.8999989]] \n",
      "\n",
      "akhir\n",
      " [[-0.08617661  0.22184212]\n",
      " [-0.51268008 -0.19159693]] [[0.28023948]\n",
      " [0.44125492]] [[-0.32973286 -0.14685115]] [[1.91517294]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "# Input dataset\n",
    "X = np.array([[0.2, 0.8]])\n",
    "\n",
    "# Output dataset\n",
    "y = np.array([[0.9]])\n",
    "\n",
    "# Seed random numbers to make calculation deterministic\n",
    "np.random.seed(1)\n",
    "\n",
    "# Initialize weights randomly with mean 0\n",
    "W1 = np.random.random((2,2)) - 0.5\n",
    "W2 = np.random.random((2,1)) - 0.5\n",
    "\n",
    "# Initialize biases randomly with mean 0\n",
    "b1 = np.random.random((1,2)) - 0.5\n",
    "b2 = np.random.random((1,1)) - 0.5\n",
    "\n",
    "print(\"awal\\n\", W1, W2, b1, b2)\n",
    "\n",
    "# Set learning rate and number of iterations\n",
    "learning_rate = 0.1\n",
    "num_iterations = 10000\n",
    "\n",
    "# Training algorithm\n",
    "for i in range(num_iterations):\n",
    "    # Feedforward\n",
    "    hidden_layer_activation = sigmoid(np.dot(X, W1) + b1)\n",
    "    output_activation = sigmoid(np.dot(hidden_layer_activation, W2) + b2)\n",
    "\n",
    "    # Calculate error\n",
    "    error = y - output_activation\n",
    "\n",
    "    # Backpropagation\n",
    "    d_predicted_output = error * sigmoid_derivative(output_activation)\n",
    "    error_hidden_layer = d_predicted_output.dot(W2.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_activation)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W2 += hidden_layer_activation.T.dot(d_predicted_output) * learning_rate\n",
    "    b2 += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
    "    W1 += X.T.dot(d_hidden_layer) * learning_rate\n",
    "    b1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "# Print final output\n",
    "print(\"\\n\")\n",
    "print(\"Output setelah training:\")\n",
    "print(output_activation, \"\\n\")\n",
    "print(\"akhir\\n\", W1, W2, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032ca8c-1601-4782-9a91-c2798c8e75ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
